# main.py

import os
import sys

# Importation des fonctions principales des diffÃ©rents modules
# NOTE: Assurez-vous que le nom des fonctions dans les modules est bien 'main_cloud_ready' ou 'main'
# Si vous avez modifiÃ© les noms, ajustez l'alias ci-dessous.
try:
    # --------------------------------------------------------------------------
    # 1. Extraction (API -> GCS)
    # Les fonctions doivent lire l'API et sauvegarder le rÃ©sultat directement sur GCS
    # --------------------------------------------------------------------------
    from src.api.get_resultats_qualite import main_cloud_ready as extract_qualite_eau
    from src.api.liste_communes import main as extract_communes_udi # Assurez-vous d'avoir ce script crÃ©Ã©
    
    # --------------------------------------------------------------------------
    # 2. Transformation (GCS/raw -> GCS/processed)
    # Les fonctions doivent lire GCS/raw, transformer, et Ã©crire GCS/processed
    # --------------------------------------------------------------------------
    from src.etl.process_data_liste_communes import main as transform_communes_udi
    from src.etl.process_resultats_qualite import main as transform_qualite_eau
    
    # --------------------------------------------------------------------------
    # 3. Chargement (GCS/processed -> BigQuery)
    # Le script final de chargement
    # --------------------------------------------------------------------------
    from src.load.load_to_bq import main # Assurez-vous d'avoir ce script crÃ©Ã©
    load_to_bigquery = main # Alias pour la clartÃ©
    
except ImportError as e:
    print(f"âŒ Erreur d'importation. Assurez-vous que tous les fichiers sont prÃ©sents et les noms des fonctions sont corrects: {e}")
    sys.exit(1)


def run_pipeline():
    """
    Orchestre l'exÃ©cution sÃ©quentielle du pipeline ETL (Extract, Transform, Load).
    """
    print("ğŸš€ DÃ©marrage du pipeline ETL de l'eau potable sur GitHub Actions...")
    
    # --- 1. EXTRACTION (API -> GCS/raw) ---
    try:
        print("\n--- Ã‰TAPE 1: Extraction des donnÃ©es API vers GCS (raw) ---")
        extract_communes_udi()
        extract_qualite_eau()
        print("âœ… Ã‰tape 1 complÃ©tÃ©e: DonnÃ©es brutes stockÃ©es dans GCS.")
    except Exception as e:
        print(f"âŒ Ã‰chec critique lors de l'extraction: {e}")
        sys.exit(1)

    # --- 2. TRANSFORMATION (GCS/raw -> GCS/processed) ---
    try:
        print("\n--- Ã‰TAPE 2: Transformation et Normalisation (Filtrage MEL) ---")
        # Le script des communes doit Ãªtre exÃ©cutÃ© en premier pour obtenir la liste des codes INSEE MEL
        transform_communes_udi() 
        # Le script de rÃ©sultats lit les brutes, utilise la liste MEL, et crÃ©e les 4 tables Parquet normalisÃ©es
        transform_qualite_eau()
        print("âœ… Ã‰tape 2 complÃ©tÃ©e: 4 tables normalisÃ©es crÃ©Ã©es sur GCS (processed).")
    except Exception as e:
        print(f"âŒ Ã‰chec critique lors de la transformation: {e}")
        sys.exit(1)

    # --- 3. CHARGEMENT (GCS/processed -> BigQuery) ---
    try:
        print("\n--- Ã‰TAPE 3: Chargement des donnÃ©es dans BigQuery ---")
        # Cette fonction doit lire les 4 fichiers Parquet de GCS/processed 
        # et les charger dans les tables BQ correspondantes.
        load_to_bigquery() 
        print("âœ… Ã‰tape 3 complÃ©tÃ©e: BigQuery alimentÃ©.")
    except Exception as e:
        print(f"âŒ Ã‰chec critique lors du chargement BigQuery: {e}")
        sys.exit(1)

    print("\nğŸ‰ Pipeline ETL exÃ©cutÃ© avec succÃ¨s de bout en bout.")

if __name__ == "__main__":
    run_pipeline()